{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Loss - 0 problem",
   "id": "48aabb7d82324e6f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T13:42:07.729801Z",
     "start_time": "2024-11-03T13:42:07.726587Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "# To consider:\n",
    "# What if the confidence for the correct class is a 0?\n",
    "print(-np.log(0))"
   ],
   "id": "a7a439697748fc77",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_155006/214172745.py:5: RuntimeWarning: divide by zero encountered in log\n",
      "  print(-np.log(0))\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T13:42:10.952877Z",
     "start_time": "2024-11-03T13:42:10.949622Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Modify the value at [0][0] so that it equals 0\n",
    "softmax_outputs2 = np.array([[0.0, 0.1, 0.2],\n",
    "                             [0.1, 0.5, 0.4],\n",
    "                             [0.02, 0.9, 0.08]])\n",
    "\n",
    "# 0-dog | 1-cat | 2-human\n",
    "# --> [dog, cat, cat]\n",
    "class_targets2 = [0, 1, 1]"
   ],
   "id": "bb6473595bb7fd3d",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T13:42:11.783370Z",
     "start_time": "2024-11-03T13:42:11.779518Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# If the confidence for the correct class is 0 then the loss for the class ends up equaling INFINITY\n",
    "# This is okay, as the loss value for only that output will be equal to 0\n",
    "# ---------> Example output: [[  INF    0.69314718    0.10536052  ]]\n",
    "neg_log2 = -np.log(softmax_outputs2[range(len(softmax_outputs2)), class_targets2])\n",
    "print(\"Loss: \", neg_log2)\n",
    "print(\"\\n-----------------------\\n\")\n",
    "\n",
    "# However, when calculating the average loss, this is where it would cause a problem\n",
    "# as the average loss would equal 0 - which would be incorrect.\n",
    "average_loss2 = np.mean(neg_log2)\n",
    "print(\"Average Loss:\", average_loss2)"
   ],
   "id": "8fbfba05733ecb86",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  [       inf 0.69314718 0.10536052]\n",
      "\n",
      "-----------------------\n",
      "\n",
      "Average Loss: inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_155006/1613827896.py:4: RuntimeWarning: divide by zero encountered in log\n",
      "  neg_log2 = -np.log(softmax_outputs2[range(len(softmax_outputs2)), class_targets2])\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---------------------------------------\n",
    "\n",
    "Solution #1: Use `numpy.clip` to clip (limit) the values in an array"
   ],
   "id": "516295e463b45967"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T13:42:16.313456Z",
     "start_time": "2024-11-03T13:42:16.309073Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# One alternative \n",
    "import numpy as np\n",
    "\n",
    "print(\"Start Range: \", -np.log(1e-7))\n",
    "print(\"End Range: \", -np.log(1-1e-7))"
   ],
   "id": "7965dbfcea01dffc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Range:  16.11809565095832\n",
      "End Range:  1.0000000494736474e-07\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Note, we begin with `-np.log(1e-7)`, which is the same as $-log_{e}(1e^{-7})$\n",
    "\n",
    "<br>\n",
    "\n",
    "Recall **$log(x) = ln(x)$**, thus:\n",
    "* $-log(1e^{-7})$\n",
    "   * $-ln(1e^{-7})$\n",
    "      * $-ln(10^{-7})$\n",
    "         * $(-1 * -7) * ln(10)$\n",
    "\n",
    "<br>\n",
    "\n",
    "Given that $ln(10)$ is approximately 2.3025:\n",
    "* $-ln(1e^{-7})$ \n",
    "   * ≈≈≈≈ $(7 * 2.3025)$\n",
    "      *  ≈≈≈≈ **16.1180**\n",
    "            * \n",
    "            \n",
    "\n",
    "----------------------\n",
    "\n",
    "Note, we begin with `-np.log(1-1e-7)`, which is the same as $-log_{e}(1-1e^-7)$\n",
    "\n",
    "<br>\n",
    "\n",
    "We will need to use Taylor Series Expansion for this.\n",
    "* Recall: $-log(1-x) ≈ -x - \\frac{x^{2}}{2} - \\frac{x^{3}}{3} - ...$\n",
    "   * For very small *x*, this simplifies to: $log(1-x) ≈ -x$\n",
    "      * Thus, for $x = -1e-7$ ---------> **$-log(1 - 1e - 7) ≈ 1e - 7$**\n",
    "\n",
    "--------------------------\n",
    "\n",
    "In terms of `np.clip`: When *a_min* is greater than *a_max*, clip\n",
    "returns an array in which all values are equal to *a_max* (see below).\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "a = np.arange(10)\n",
    "\n",
    "# array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "a \n",
    "\n",
    "# array([1, 1, 2, 3, 4, 5, 6, 7, 8, 8])\n",
    "np.clip(a, 1, 8)\n",
    "\n",
    "# array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
    "np.clip(a, 8, 1)\n",
    "```"
   ],
   "id": "c53eeb819f110bb2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Solution\n",
    "y_pred_clipped = np.clip(y_pred, 0e-7, 1 - 1e-7)"
   ],
   "id": "bc5a324f740f9bb"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
